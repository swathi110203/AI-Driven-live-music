{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddf64de-d657-41b6-84b3-fc79244e957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sumanth\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42cb989e-8d14-4a9d-9769-8f382f13c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"D:/MusicDataset/Metadata_Train.csv\")\n",
    "df2=pd.read_csv(\"D:/MusicDataset/Metadata_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b725719-707b-415c-bec4-68ee732075f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-E1-Major 00.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-E1-Major 01.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-E1-Major 02.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-E1-Major 03.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-E1-Major 04.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>sawaar loon.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>soona soona.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>summane.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>tangali.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>tere bin.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2722 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               FileName         Class\n",
       "0     1-E1-Major 00.wav  Sound_Guitar\n",
       "1     1-E1-Major 01.wav  Sound_Guitar\n",
       "2     1-E1-Major 02.wav  Sound_Guitar\n",
       "3     1-E1-Major 03.wav  Sound_Guitar\n",
       "4     1-E1-Major 04.wav  Sound_Guitar\n",
       "...                 ...           ...\n",
       "2717    sawaar loon.wav   Sound_Vocal\n",
       "2718    soona soona.wav   Sound_Vocal\n",
       "2719        summane.wav   Sound_Vocal\n",
       "2720        tangali.wav   Sound_Vocal\n",
       "2721       tere bin.wav   Sound_Vocal\n",
       "\n",
       "[2722 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e376986-36a8-4d84-8cbb-5aebb7fcfd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "Sound_Guitar    700\n",
      "Sound_Drum      700\n",
      "Sound_Violin    700\n",
      "Sound_Piano     529\n",
      "Sound_Vocal      93\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Sound_Guitar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m22\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcountplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\seaborn\\categorical.py:2943\u001b[0m, in \u001b[0;36mcountplot\u001b[1;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, width, dodge, ax, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pass values for both `x` and `y`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2943\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_CountPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrorbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2946\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdodge\u001b[49m\n\u001b[0;32m   2948\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2950\u001b[0m plotter\u001b[38;5;241m.\u001b[39mvalue_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\seaborn\\categorical.py:1530\u001b[0m, in \u001b[0;36m_BarPlotter.__init__\u001b[1;34m(self, x, y, hue, data, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, hue, data, order, hue_order,\n\u001b[0;32m   1526\u001b[0m              estimator, errorbar, n_boot, units, seed,\n\u001b[0;32m   1527\u001b[0m              orient, color, palette, saturation, width,\n\u001b[0;32m   1528\u001b[0m              errcolor, errwidth, capsize, dodge):\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the plotter.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1530\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestablish_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m                             \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1532\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestablish_colors(color, palette, saturation)\n\u001b[0;32m   1533\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_statistic(estimator, errorbar, n_boot, seed)\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\seaborn\\categorical.py:516\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_variables\u001b[1;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[0;32m    513\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Convert to a list of arrays, the common representation\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m plot_data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mplot_data\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;66;03m# The group names will just be numeric indices\u001b[39;00m\n\u001b[0;32m    519\u001b[0m group_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(plot_data)))\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\seaborn\\categorical.py:516\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    513\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Convert to a list of arrays, the common representation\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m plot_data \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m plot_data]\n\u001b[0;32m    518\u001b[0m \u001b[38;5;66;03m# The group names will just be numeric indices\u001b[39;00m\n\u001b[0;32m    519\u001b[0m group_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(plot_data)))\n",
      "File \u001b[1;32m~\\anaconda\\Lib\\site-packages\\pandas\\core\\series.py:917\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    916\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m--> 917\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    919\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Sound_Guitar'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df['Class'].value_counts())\n",
    "plt.figure(figsize=(22,10))\n",
    "sns.countplot(df['Class'])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2086ecb-3694-4d3a-8c38-8510c8d9c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['Class'].isin(['Sound_Violin'])].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f21436ea-6138-4181-be28-7686e2658e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-E1-Major 00.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-E1-Major 01.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-E1-Major 02.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-E1-Major 03.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-E1-Major 04.wav</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>sawaar loon.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>soona soona.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>summane.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>tangali.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>tere bin.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               FileName         Class\n",
       "0     1-E1-Major 00.wav  Sound_Guitar\n",
       "1     1-E1-Major 01.wav  Sound_Guitar\n",
       "2     1-E1-Major 02.wav  Sound_Guitar\n",
       "3     1-E1-Major 03.wav  Sound_Guitar\n",
       "4     1-E1-Major 04.wav  Sound_Guitar\n",
       "...                 ...           ...\n",
       "2717    sawaar loon.wav   Sound_Vocal\n",
       "2718    soona soona.wav   Sound_Vocal\n",
       "2719        summane.wav   Sound_Vocal\n",
       "2720        tangali.wav   Sound_Vocal\n",
       "2721       tere bin.wav   Sound_Vocal\n",
       "\n",
       "[2022 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1736bfad-2797-48c7-bc78-9da988c7d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(df2[df2['Class'].isin(['Sound_Violin'])].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f606cc63-05c1-4500-9e63-f71fe7b45f04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acoustic-guitar-logo-13084.wav</td>\n",
       "      <td>Sound_Guiatr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guitar-chords-70663.wav</td>\n",
       "      <td>Sound_Guiatr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guitar-intro-110935.wav</td>\n",
       "      <td>Sound_Guiatr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>guitar-solo-27194.wav</td>\n",
       "      <td>Sound_Guiatr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>guitar-solo-5999.wav</td>\n",
       "      <td>Sound_Guiatr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tere naina.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tu hi meri shab.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tu hi re.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tujhe kitna.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>yaman.wav</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          FileName         Class\n",
       "0   acoustic-guitar-logo-13084.wav  Sound_Guiatr\n",
       "1          guitar-chords-70663.wav  Sound_Guiatr\n",
       "2          guitar-intro-110935.wav  Sound_Guiatr\n",
       "3            guitar-solo-27194.wav  Sound_Guiatr\n",
       "4             guitar-solo-5999.wav  Sound_Guiatr\n",
       "..                             ...           ...\n",
       "93                  tere naina.wav   Sound_Vocal\n",
       "94             tu hi meri shab.wav   Sound_Vocal\n",
       "95                    tu hi re.wav   Sound_Vocal\n",
       "96                 tujhe kitna.wav   Sound_Vocal\n",
       "97                       yaman.wav   Sound_Vocal\n",
       "\n",
       "[78 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0e81d0d-4539-4050-94ec-79e3201c7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_extractor(file):\n",
    "    \n",
    "    audio,sample_rate=librosa.load(file_name,res_type='kaiser_fast')\n",
    "    mfccs_features=librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n",
    "    mfccs_scaled_features =np.mean(mfccs_features.T,axis=0)\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "550daaea-33a7-41d4-94f9-ff2df3f92f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022it [07:44,  4.36it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming df contains the DataFrame with columns \"FileName\" and \"Class\"\n",
    "extracted_features = []\n",
    "\n",
    "for index_num, row in tqdm(df.iterrows()):\n",
    "    file_name = os.path.abspath(os.path.join(\"D:/MusicDataset/Train_submission/Train_submission\", str(row[\"FileName\"])))\n",
    "    final_class_label = row[\"Class\"]\n",
    "    data = Feature_extractor(file_name)\n",
    "    extracted_features.append([data, final_class_label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb6eb96-7864-4d3a-9dbf-11b0cbe8232d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-388.4289, 205.19734, 7.863611, 39.286667, 13...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-359.54538, 171.62688, 10.192535, 37.61143, 1...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-347.31915, 178.11375, 2.1611729, 38.960228, ...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-389.92075, 177.8204, 10.302906, 42.16702, 14...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-372.23615, 161.71027, 10.579021, 45.089127, ...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-391.01813, 173.12811, 18.012999, 37.28042, 1...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-386.7482, 162.40793, 15.373853, 42.025448, 2...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-408.49643, 160.14922, 20.34738, 41.80766, 18...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-398.09885, 147.52005, 24.257866, 43.7894, 3....</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-411.7316, 151.5299, 22.383932, 37.782017, 2....</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-418.03424, 152.96887, 24.993553, 41.93719, 9...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[-372.1232, 199.836, -2.09703, 39.002117, 17.3...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[-375.02094, 183.23709, 10.461864, 37.27481, 1...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[-393.6625, 192.27861, 21.117407, 39.228924, 1...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[-388.14496, 176.80055, 18.275787, 40.78644, 7...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-378.6451, 178.78622, 13.352617, 34.78991, 6....</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[-411.15717, 169.85274, 22.245144, 42.33182, 9...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[-381.55118, 164.12683, 20.477444, 43.521786, ...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[-396.85492, 166.25247, 18.359821, 41.19802, 2...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[-410.05707, 156.49147, 24.350708, 37.764313, ...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features         class\n",
       "0   [-388.4289, 205.19734, 7.863611, 39.286667, 13...  Sound_Guitar\n",
       "1   [-359.54538, 171.62688, 10.192535, 37.61143, 1...  Sound_Guitar\n",
       "2   [-347.31915, 178.11375, 2.1611729, 38.960228, ...  Sound_Guitar\n",
       "3   [-389.92075, 177.8204, 10.302906, 42.16702, 14...  Sound_Guitar\n",
       "4   [-372.23615, 161.71027, 10.579021, 45.089127, ...  Sound_Guitar\n",
       "5   [-391.01813, 173.12811, 18.012999, 37.28042, 1...  Sound_Guitar\n",
       "6   [-386.7482, 162.40793, 15.373853, 42.025448, 2...  Sound_Guitar\n",
       "7   [-408.49643, 160.14922, 20.34738, 41.80766, 18...  Sound_Guitar\n",
       "8   [-398.09885, 147.52005, 24.257866, 43.7894, 3....  Sound_Guitar\n",
       "9   [-411.7316, 151.5299, 22.383932, 37.782017, 2....  Sound_Guitar\n",
       "10  [-418.03424, 152.96887, 24.993553, 41.93719, 9...  Sound_Guitar\n",
       "11  [-372.1232, 199.836, -2.09703, 39.002117, 17.3...  Sound_Guitar\n",
       "12  [-375.02094, 183.23709, 10.461864, 37.27481, 1...  Sound_Guitar\n",
       "13  [-393.6625, 192.27861, 21.117407, 39.228924, 1...  Sound_Guitar\n",
       "14  [-388.14496, 176.80055, 18.275787, 40.78644, 7...  Sound_Guitar\n",
       "15  [-378.6451, 178.78622, 13.352617, 34.78991, 6....  Sound_Guitar\n",
       "16  [-411.15717, 169.85274, 22.245144, 42.33182, 9...  Sound_Guitar\n",
       "17  [-381.55118, 164.12683, 20.477444, 43.521786, ...  Sound_Guitar\n",
       "18  [-396.85492, 166.25247, 18.359821, 41.19802, 2...  Sound_Guitar\n",
       "19  [-410.05707, 156.49147, 24.350708, 37.764313, ...  Sound_Guitar"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['features','class'])\n",
    "extracted_features_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab7050d-605e-4e93-a7af-bfda575ed060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-388.4289, 205.19734, 7.863611, 39.286667, 13...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-359.54538, 171.62688, 10.192535, 37.61143, 1...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-347.31915, 178.11375, 2.1611729, 38.960228, ...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-389.92075, 177.8204, 10.302906, 42.16702, 14...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-372.23615, 161.71027, 10.579021, 45.089127, ...</td>\n",
       "      <td>Sound_Guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>[-484.7601, 104.058525, 15.061387, 24.160992, ...</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>[-395.24832, 105.78999, -4.152595, 23.851385, ...</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>[-384.6769, 114.452095, 0.62603873, 20.970564,...</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>[-432.14066, 88.12449, 2.1225023, -1.633527, -...</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>[-400.0713, 91.85815, 6.450053, 23.285162, 5.0...</td>\n",
       "      <td>Sound_Vocal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               features         class\n",
       "0     [-388.4289, 205.19734, 7.863611, 39.286667, 13...  Sound_Guitar\n",
       "1     [-359.54538, 171.62688, 10.192535, 37.61143, 1...  Sound_Guitar\n",
       "2     [-347.31915, 178.11375, 2.1611729, 38.960228, ...  Sound_Guitar\n",
       "3     [-389.92075, 177.8204, 10.302906, 42.16702, 14...  Sound_Guitar\n",
       "4     [-372.23615, 161.71027, 10.579021, 45.089127, ...  Sound_Guitar\n",
       "...                                                 ...           ...\n",
       "2017  [-484.7601, 104.058525, 15.061387, 24.160992, ...   Sound_Vocal\n",
       "2018  [-395.24832, 105.78999, -4.152595, 23.851385, ...   Sound_Vocal\n",
       "2019  [-384.6769, 114.452095, 0.62603873, 20.970564,...   Sound_Vocal\n",
       "2020  [-432.14066, 88.12449, 2.1225023, -1.633527, -...   Sound_Vocal\n",
       "2021  [-400.0713, 91.85815, 6.450053, 23.285162, 5.0...   Sound_Vocal\n",
       "\n",
       "[2022 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "139e9eda-7e88-4342-a176-eb146ab5caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(extracted_features_df['features'].tolist())\n",
    "y=np.array(extracted_features_df[\"class\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc2f2362-5a38-4217-8a09-043a0ac3b404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2502852c-e769-4e1a-9284-f0cf118fdc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2022, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd5c40bc-6fb7-408d-9400-2fb9fb42ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE=LabelEncoder()\n",
    "y=to_categorical(LE.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6325ccc-f5d5-4ecf-b3ec-3ec43ad853bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e69808bf-d896-4b08-9307-9e8f850fcabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c632d75-f881-407e-99a2-f6c08d81f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=y.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65f0da43-14c2-4edf-8bb2-09b7a2fd931b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3fa4548-57f5-47ea-aca0-177d08868d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sumanth\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78634d5d-bf65-4250-bf66-ef71be0cadb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85004 (332.05 KB)\n",
      "Trainable params: 85004 (332.05 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c283f148-dbc1-4ca0-9061-c083fefc62ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sumanth\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97a2024d-1ea4-4a01-9b40-b6ee57aea4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Sumanth\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sumanth\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "34/51 [===================>..........] - ETA: 0s - loss: 14.1108 - accuracy: 0.3686 \n",
      "Epoch 1: val_loss improved from inf to 1.05208, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 2s 9ms/step - loss: 10.9553 - accuracy: 0.3958 - val_loss: 1.0521 - val_accuracy: 0.6469\n",
      "Epoch 2/100\n",
      "45/51 [=========================>....] - ETA: 0s - loss: 3.1496 - accuracy: 0.4479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumanth\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 1.05208 to 0.96901, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 3.0684 - accuracy: 0.4447 - val_loss: 0.9690 - val_accuracy: 0.5556\n",
      "Epoch 3/100\n",
      "46/51 [==========================>...] - ETA: 0s - loss: 1.7612 - accuracy: 0.4925\n",
      "Epoch 3: val_loss did not improve from 0.96901\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 1.7377 - accuracy: 0.4935 - val_loss: 0.9738 - val_accuracy: 0.5457\n",
      "Epoch 4/100\n",
      "50/51 [============================>.] - ETA: 0s - loss: 1.3702 - accuracy: 0.5344\n",
      "Epoch 4: val_loss improved from 0.96901 to 0.95518, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 1.3707 - accuracy: 0.5325 - val_loss: 0.9552 - val_accuracy: 0.5926\n",
      "Epoch 5/100\n",
      "44/51 [========================>.....] - ETA: 0s - loss: 1.1447 - accuracy: 0.5561\n",
      "Epoch 5: val_loss improved from 0.95518 to 0.92011, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 1.1342 - accuracy: 0.5609 - val_loss: 0.9201 - val_accuracy: 0.5753\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.0243 - accuracy: 0.5949\n",
      "Epoch 6: val_loss improved from 0.92011 to 0.88624, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 1.0243 - accuracy: 0.5949 - val_loss: 0.8862 - val_accuracy: 0.6173\n",
      "Epoch 7/100\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.9525 - accuracy: 0.6194\n",
      "Epoch 7: val_loss improved from 0.88624 to 0.82058, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.9487 - accuracy: 0.6209 - val_loss: 0.8206 - val_accuracy: 0.5951\n",
      "Epoch 8/100\n",
      "41/51 [=======================>......] - ETA: 0s - loss: 0.9176 - accuracy: 0.6265\n",
      "Epoch 8: val_loss improved from 0.82058 to 0.80393, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.9161 - accuracy: 0.6240 - val_loss: 0.8039 - val_accuracy: 0.6494\n",
      "Epoch 9/100\n",
      "38/51 [=====================>........] - ETA: 0s - loss: 0.8823 - accuracy: 0.6472\n",
      "Epoch 9: val_loss improved from 0.80393 to 0.73116, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.8628 - accuracy: 0.6518 - val_loss: 0.7312 - val_accuracy: 0.6741\n",
      "Epoch 10/100\n",
      "43/51 [========================>.....] - ETA: 0s - loss: 0.8055 - accuracy: 0.6788\n",
      "Epoch 10: val_loss improved from 0.73116 to 0.67186, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.8006 - accuracy: 0.6840 - val_loss: 0.6719 - val_accuracy: 0.7259\n",
      "Epoch 11/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.7689 - accuracy: 0.6972\n",
      "Epoch 11: val_loss improved from 0.67186 to 0.66803, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.7672 - accuracy: 0.7032 - val_loss: 0.6680 - val_accuracy: 0.7654\n",
      "Epoch 12/100\n",
      "41/51 [=======================>......] - ETA: 0s - loss: 0.6569 - accuracy: 0.7569\n",
      "Epoch 12: val_loss improved from 0.66803 to 0.62518, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.7421 - val_loss: 0.6252 - val_accuracy: 0.7877\n",
      "Epoch 13/100\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 0.7144 - accuracy: 0.7250\n",
      "Epoch 13: val_loss did not improve from 0.62518\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.7076 - accuracy: 0.7285 - val_loss: 0.6375 - val_accuracy: 0.7951\n",
      "Epoch 14/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.6428 - accuracy: 0.7753\n",
      "Epoch 14: val_loss improved from 0.62518 to 0.60691, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.7730 - val_loss: 0.6069 - val_accuracy: 0.8025\n",
      "Epoch 15/100\n",
      "46/51 [==========================>...] - ETA: 0s - loss: 0.6189 - accuracy: 0.7595\n",
      "Epoch 15: val_loss improved from 0.60691 to 0.55793, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.7576 - val_loss: 0.5579 - val_accuracy: 0.8099\n",
      "Epoch 16/100\n",
      "46/51 [==========================>...] - ETA: 0s - loss: 0.6114 - accuracy: 0.7819\n",
      "Epoch 16: val_loss did not improve from 0.55793\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.7823 - val_loss: 0.5614 - val_accuracy: 0.8247\n",
      "Epoch 17/100\n",
      "46/51 [==========================>...] - ETA: 0s - loss: 0.6053 - accuracy: 0.7833\n",
      "Epoch 17: val_loss did not improve from 0.55793\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.7891 - val_loss: 0.5601 - val_accuracy: 0.8222\n",
      "Epoch 18/100\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.5916 - accuracy: 0.7923\n",
      "Epoch 18: val_loss improved from 0.55793 to 0.51231, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.7910 - val_loss: 0.5123 - val_accuracy: 0.8296\n",
      "Epoch 19/100\n",
      "46/51 [==========================>...] - ETA: 0s - loss: 0.5498 - accuracy: 0.7962\n",
      "Epoch 19: val_loss improved from 0.51231 to 0.50722, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.8002 - val_loss: 0.5072 - val_accuracy: 0.8247\n",
      "Epoch 20/100\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.5318 - accuracy: 0.8086\n",
      "Epoch 20: val_loss improved from 0.50722 to 0.49578, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.8077 - val_loss: 0.4958 - val_accuracy: 0.8370\n",
      "Epoch 21/100\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.5011 - accuracy: 0.8246\n",
      "Epoch 21: val_loss improved from 0.49578 to 0.47589, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.8219 - val_loss: 0.4759 - val_accuracy: 0.8173\n",
      "Epoch 22/100\n",
      "41/51 [=======================>......] - ETA: 0s - loss: 0.4971 - accuracy: 0.8209\n",
      "Epoch 22: val_loss improved from 0.47589 to 0.46079, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.8250 - val_loss: 0.4608 - val_accuracy: 0.8370\n",
      "Epoch 23/100\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.4758 - accuracy: 0.8275\n",
      "Epoch 23: val_loss improved from 0.46079 to 0.42652, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.8256 - val_loss: 0.4265 - val_accuracy: 0.8469\n",
      "Epoch 24/100\n",
      "47/51 [==========================>...] - ETA: 0s - loss: 0.4792 - accuracy: 0.8185\n",
      "Epoch 24: val_loss improved from 0.42652 to 0.41842, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.8207 - val_loss: 0.4184 - val_accuracy: 0.8543\n",
      "Epoch 25/100\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.4700 - accuracy: 0.8265\n",
      "Epoch 25: val_loss improved from 0.41842 to 0.39327, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8275 - val_loss: 0.3933 - val_accuracy: 0.8568\n",
      "Epoch 26/100\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.4465 - accuracy: 0.8444\n",
      "Epoch 26: val_loss improved from 0.39327 to 0.38984, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8479 - val_loss: 0.3898 - val_accuracy: 0.8568\n",
      "Epoch 27/100\n",
      "44/51 [========================>.....] - ETA: 0s - loss: 0.4343 - accuracy: 0.8480\n",
      "Epoch 27: val_loss improved from 0.38984 to 0.38599, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.8485 - val_loss: 0.3860 - val_accuracy: 0.8617\n",
      "Epoch 28/100\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.4003 - accuracy: 0.8635\n",
      "Epoch 28: val_loss improved from 0.38599 to 0.34796, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8633 - val_loss: 0.3480 - val_accuracy: 0.8790\n",
      "Epoch 29/100\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 0.3706 - accuracy: 0.8680\n",
      "Epoch 29: val_loss did not improve from 0.34796\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.8658 - val_loss: 0.3481 - val_accuracy: 0.8864\n",
      "Epoch 30/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.3622 - accuracy: 0.8780\n",
      "Epoch 30: val_loss did not improve from 0.34796\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8776 - val_loss: 0.3492 - val_accuracy: 0.8864\n",
      "Epoch 31/100\n",
      "33/51 [==================>...........] - ETA: 0s - loss: 0.3725 - accuracy: 0.8712\n",
      "Epoch 31: val_loss improved from 0.34796 to 0.31462, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8745 - val_loss: 0.3146 - val_accuracy: 0.9012\n",
      "Epoch 32/100\n",
      "44/51 [========================>.....] - ETA: 0s - loss: 0.3747 - accuracy: 0.8786\n",
      "Epoch 32: val_loss did not improve from 0.31462\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8794 - val_loss: 0.3560 - val_accuracy: 0.8889\n",
      "Epoch 33/100\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 0.3876 - accuracy: 0.8711\n",
      "Epoch 33: val_loss did not improve from 0.31462\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8720 - val_loss: 0.3167 - val_accuracy: 0.8988\n",
      "Epoch 34/100\n",
      "41/51 [=======================>......] - ETA: 0s - loss: 0.3530 - accuracy: 0.8788\n",
      "Epoch 34: val_loss improved from 0.31462 to 0.28374, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8776 - val_loss: 0.2837 - val_accuracy: 0.9160\n",
      "Epoch 35/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.3143 - accuracy: 0.8876\n",
      "Epoch 35: val_loss did not improve from 0.28374\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.8899 - val_loss: 0.2859 - val_accuracy: 0.9111\n",
      "Epoch 36/100\n",
      "41/51 [=======================>......] - ETA: 0s - loss: 0.2897 - accuracy: 0.9047\n",
      "Epoch 36: val_loss improved from 0.28374 to 0.27061, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.8986 - val_loss: 0.2706 - val_accuracy: 0.9235\n",
      "Epoch 37/100\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 0.3155 - accuracy: 0.8969\n",
      "Epoch 37: val_loss did not improve from 0.27061\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3062 - accuracy: 0.8986 - val_loss: 0.2735 - val_accuracy: 0.9136\n",
      "Epoch 38/100\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 0.2976 - accuracy: 0.9039\n",
      "Epoch 38: val_loss improved from 0.27061 to 0.25901, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2923 - accuracy: 0.9066 - val_loss: 0.2590 - val_accuracy: 0.9235\n",
      "Epoch 39/100\n",
      "45/51 [=========================>....] - ETA: 0s - loss: 0.3113 - accuracy: 0.8910\n",
      "Epoch 39: val_loss did not improve from 0.25901\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3062 - accuracy: 0.8930 - val_loss: 0.2594 - val_accuracy: 0.9185\n",
      "Epoch 40/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.2916 - accuracy: 0.9062\n",
      "Epoch 40: val_loss did not improve from 0.25901\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.9109 - val_loss: 0.2698 - val_accuracy: 0.9012\n",
      "Epoch 41/100\n",
      "37/51 [====================>.........] - ETA: 0s - loss: 0.2779 - accuracy: 0.9122\n",
      "Epoch 41: val_loss improved from 0.25901 to 0.24857, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.9103 - val_loss: 0.2486 - val_accuracy: 0.9284\n",
      "Epoch 42/100\n",
      "41/51 [=======================>......] - ETA: 0s - loss: 0.2626 - accuracy: 0.9146\n",
      "Epoch 42: val_loss improved from 0.24857 to 0.24248, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.9103 - val_loss: 0.2425 - val_accuracy: 0.9259\n",
      "Epoch 43/100\n",
      "38/51 [=====================>........] - ETA: 0s - loss: 0.2667 - accuracy: 0.9062\n",
      "Epoch 43: val_loss did not improve from 0.24248\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2570 - accuracy: 0.9091 - val_loss: 0.2452 - val_accuracy: 0.9235\n",
      "Epoch 44/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.2159 - accuracy: 0.9286\n",
      "Epoch 44: val_loss improved from 0.24248 to 0.22474, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2369 - accuracy: 0.9215 - val_loss: 0.2247 - val_accuracy: 0.9309\n",
      "Epoch 45/100\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 0.2179 - accuracy: 0.9352\n",
      "Epoch 45: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 0.9283 - val_loss: 0.2570 - val_accuracy: 0.9235\n",
      "Epoch 46/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.2491 - accuracy: 0.9196\n",
      "Epoch 46: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.9165 - val_loss: 0.2376 - val_accuracy: 0.9259\n",
      "Epoch 47/100\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.2397 - accuracy: 0.9160\n",
      "Epoch 47: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2408 - accuracy: 0.9165 - val_loss: 0.2358 - val_accuracy: 0.9259\n",
      "Epoch 48/100\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 0.2374 - accuracy: 0.9190\n",
      "Epoch 48: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2320 - accuracy: 0.9215 - val_loss: 0.2419 - val_accuracy: 0.9235\n",
      "Epoch 49/100\n",
      "46/51 [==========================>...] - ETA: 0s - loss: 0.2395 - accuracy: 0.9185\n",
      "Epoch 49: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.9190 - val_loss: 0.2317 - val_accuracy: 0.9235\n",
      "Epoch 50/100\n",
      "36/51 [====================>.........] - ETA: 0s - loss: 0.2015 - accuracy: 0.9375\n",
      "Epoch 50: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2247 - accuracy: 0.9338 - val_loss: 0.2316 - val_accuracy: 0.9259\n",
      "Epoch 51/100\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 0.2214 - accuracy: 0.9423\n",
      "Epoch 51: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9425 - val_loss: 0.2790 - val_accuracy: 0.9235\n",
      "Epoch 52/100\n",
      "45/51 [=========================>....] - ETA: 0s - loss: 0.2249 - accuracy: 0.9278\n",
      "Epoch 52: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2362 - accuracy: 0.9270 - val_loss: 0.2296 - val_accuracy: 0.9235\n",
      "Epoch 53/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.2123 - accuracy: 0.9345\n",
      "Epoch 53: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9338 - val_loss: 0.2423 - val_accuracy: 0.9185\n",
      "Epoch 54/100\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 0.2083 - accuracy: 0.9273\n",
      "Epoch 54: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2046 - accuracy: 0.9301 - val_loss: 0.2557 - val_accuracy: 0.9235\n",
      "Epoch 55/100\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.2120 - accuracy: 0.9355\n",
      "Epoch 55: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2065 - accuracy: 0.9369 - val_loss: 0.2269 - val_accuracy: 0.9284\n",
      "Epoch 56/100\n",
      "38/51 [=====================>........] - ETA: 0s - loss: 0.2105 - accuracy: 0.9367\n",
      "Epoch 56: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2080 - accuracy: 0.9394 - val_loss: 0.2363 - val_accuracy: 0.9235\n",
      "Epoch 57/100\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 0.1823 - accuracy: 0.9375\n",
      "Epoch 57: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1905 - accuracy: 0.9363 - val_loss: 0.2402 - val_accuracy: 0.9259\n",
      "Epoch 58/100\n",
      "41/51 [=======================>......] - ETA: 0s - loss: 0.1753 - accuracy: 0.9428\n",
      "Epoch 58: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1787 - accuracy: 0.9425 - val_loss: 0.2575 - val_accuracy: 0.9111\n",
      "Epoch 59/100\n",
      "47/51 [==========================>...] - ETA: 0s - loss: 0.1819 - accuracy: 0.9388\n",
      "Epoch 59: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9375 - val_loss: 0.2344 - val_accuracy: 0.9111\n",
      "Epoch 60/100\n",
      "43/51 [========================>.....] - ETA: 0s - loss: 0.1731 - accuracy: 0.9506\n",
      "Epoch 60: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1751 - accuracy: 0.9493 - val_loss: 0.2430 - val_accuracy: 0.9309\n",
      "Epoch 61/100\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.1701 - accuracy: 0.9460\n",
      "Epoch 61: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9474 - val_loss: 0.2396 - val_accuracy: 0.9309\n",
      "Epoch 62/100\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 0.1701 - accuracy: 0.9445\n",
      "Epoch 62: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.9456 - val_loss: 0.2463 - val_accuracy: 0.9259\n",
      "Epoch 63/100\n",
      "41/51 [=======================>......] - ETA: 0s - loss: 0.1921 - accuracy: 0.9444\n",
      "Epoch 63: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9468 - val_loss: 0.2447 - val_accuracy: 0.9309\n",
      "Epoch 64/100\n",
      "43/51 [========================>.....] - ETA: 0s - loss: 0.1655 - accuracy: 0.9491\n",
      "Epoch 64: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9474 - val_loss: 0.2603 - val_accuracy: 0.9259\n",
      "Epoch 65/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.1755 - accuracy: 0.9412\n",
      "Epoch 65: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1721 - accuracy: 0.9437 - val_loss: 0.2445 - val_accuracy: 0.9358\n",
      "Epoch 66/100\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 0.1578 - accuracy: 0.9453\n",
      "Epoch 66: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1688 - accuracy: 0.9431 - val_loss: 0.2476 - val_accuracy: 0.9185\n",
      "Epoch 67/100\n",
      "47/51 [==========================>...] - ETA: 0s - loss: 0.1656 - accuracy: 0.9402\n",
      "Epoch 67: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9394 - val_loss: 0.2259 - val_accuracy: 0.9235\n",
      "Epoch 68/100\n",
      "36/51 [====================>.........] - ETA: 0s - loss: 0.1194 - accuracy: 0.9592\n",
      "Epoch 68: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9561 - val_loss: 0.2499 - val_accuracy: 0.9383\n",
      "Epoch 69/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.1753 - accuracy: 0.9435\n",
      "Epoch 69: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9462 - val_loss: 0.2642 - val_accuracy: 0.9407\n",
      "Epoch 70/100\n",
      "43/51 [========================>.....] - ETA: 0s - loss: 0.1701 - accuracy: 0.9491\n",
      "Epoch 70: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 0.9493 - val_loss: 0.2448 - val_accuracy: 0.9432\n",
      "Epoch 71/100\n",
      "25/51 [=============>................] - ETA: 0s - loss: 0.1523 - accuracy: 0.9525\n",
      "Epoch 71: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9481 - val_loss: 0.2402 - val_accuracy: 0.9185\n",
      "Epoch 72/100\n",
      "47/51 [==========================>...] - ETA: 0s - loss: 0.1448 - accuracy: 0.9548\n",
      "Epoch 72: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9542 - val_loss: 0.2566 - val_accuracy: 0.9259\n",
      "Epoch 73/100\n",
      "35/51 [===================>..........] - ETA: 0s - loss: 0.1320 - accuracy: 0.9607\n",
      "Epoch 73: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9610 - val_loss: 0.2449 - val_accuracy: 0.9284\n",
      "Epoch 74/100\n",
      "47/51 [==========================>...] - ETA: 0s - loss: 0.1190 - accuracy: 0.9628\n",
      "Epoch 74: val_loss did not improve from 0.22474\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9635 - val_loss: 0.2316 - val_accuracy: 0.9383\n",
      "Epoch 75/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.1480 - accuracy: 0.9554\n",
      "Epoch 75: val_loss improved from 0.22474 to 0.20000, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9555 - val_loss: 0.2000 - val_accuracy: 0.9333\n",
      "Epoch 76/100\n",
      "46/51 [==========================>...] - ETA: 0s - loss: 0.1304 - accuracy: 0.9538\n",
      "Epoch 76: val_loss did not improve from 0.20000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9524 - val_loss: 0.2319 - val_accuracy: 0.9284\n",
      "Epoch 77/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.1357 - accuracy: 0.9598\n",
      "Epoch 77: val_loss improved from 0.20000 to 0.19789, saving model to audio_classifier_model\\audio_classification.hdf5\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.9617 - val_loss: 0.1979 - val_accuracy: 0.9407\n",
      "Epoch 78/100\n",
      "34/51 [===================>..........] - ETA: 0s - loss: 0.1479 - accuracy: 0.9568\n",
      "Epoch 78: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1423 - accuracy: 0.9555 - val_loss: 0.2264 - val_accuracy: 0.9309\n",
      "Epoch 79/100\n",
      "46/51 [==========================>...] - ETA: 0s - loss: 0.1194 - accuracy: 0.9626\n",
      "Epoch 79: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1190 - accuracy: 0.9623 - val_loss: 0.2365 - val_accuracy: 0.9407\n",
      "Epoch 80/100\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 0.1351 - accuracy: 0.9578\n",
      "Epoch 80: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1248 - accuracy: 0.9617 - val_loss: 0.2274 - val_accuracy: 0.9407\n",
      "Epoch 81/100\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 0.1242 - accuracy: 0.9688\n",
      "Epoch 81: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1315 - accuracy: 0.9660 - val_loss: 0.2313 - val_accuracy: 0.9358\n",
      "Epoch 82/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.1124 - accuracy: 0.9643\n",
      "Epoch 82: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9647 - val_loss: 0.2591 - val_accuracy: 0.9358\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.9586\n",
      "Epoch 83: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9586 - val_loss: 0.2448 - val_accuracy: 0.9235\n",
      "Epoch 84/100\n",
      "38/51 [=====================>........] - ETA: 0s - loss: 0.1377 - accuracy: 0.9556\n",
      "Epoch 84: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1400 - accuracy: 0.9555 - val_loss: 0.2617 - val_accuracy: 0.9210\n",
      "Epoch 85/100\n",
      "37/51 [====================>.........] - ETA: 0s - loss: 0.1145 - accuracy: 0.9603\n",
      "Epoch 85: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.9604 - val_loss: 0.2512 - val_accuracy: 0.9457\n",
      "Epoch 86/100\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 0.1552 - accuracy: 0.9546\n",
      "Epoch 86: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9561 - val_loss: 0.2257 - val_accuracy: 0.9432\n",
      "Epoch 87/100\n",
      "44/51 [========================>.....] - ETA: 0s - loss: 0.1475 - accuracy: 0.9574\n",
      "Epoch 87: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1396 - accuracy: 0.9604 - val_loss: 0.2335 - val_accuracy: 0.9432\n",
      "Epoch 88/100\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 0.1279 - accuracy: 0.9642\n",
      "Epoch 88: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9629 - val_loss: 0.2401 - val_accuracy: 0.9432\n",
      "Epoch 89/100\n",
      "36/51 [====================>.........] - ETA: 0s - loss: 0.1427 - accuracy: 0.9601\n",
      "Epoch 89: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1336 - accuracy: 0.9598 - val_loss: 0.2350 - val_accuracy: 0.9457\n",
      "Epoch 90/100\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 0.1324 - accuracy: 0.9567\n",
      "Epoch 90: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9567 - val_loss: 0.2526 - val_accuracy: 0.9432\n",
      "Epoch 91/100\n",
      "37/51 [====================>.........] - ETA: 0s - loss: 0.1269 - accuracy: 0.9628\n",
      "Epoch 91: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9610 - val_loss: 0.2450 - val_accuracy: 0.9284\n",
      "Epoch 92/100\n",
      "37/51 [====================>.........] - ETA: 0s - loss: 0.1276 - accuracy: 0.9603\n",
      "Epoch 92: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1341 - accuracy: 0.9586 - val_loss: 0.2231 - val_accuracy: 0.9457\n",
      "Epoch 93/100\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 0.1339 - accuracy: 0.9543\n",
      "Epoch 93: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1251 - accuracy: 0.9579 - val_loss: 0.2247 - val_accuracy: 0.9383\n",
      "Epoch 94/100\n",
      "43/51 [========================>.....] - ETA: 0s - loss: 0.1176 - accuracy: 0.9615\n",
      "Epoch 94: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9629 - val_loss: 0.2373 - val_accuracy: 0.9457\n",
      "Epoch 95/100\n",
      "45/51 [=========================>....] - ETA: 0s - loss: 0.1005 - accuracy: 0.9681\n",
      "Epoch 95: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9685 - val_loss: 0.2847 - val_accuracy: 0.9333\n",
      "Epoch 96/100\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 0.1197 - accuracy: 0.9623\n",
      "Epoch 96: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1203 - accuracy: 0.9629 - val_loss: 0.2473 - val_accuracy: 0.9284\n",
      "Epoch 97/100\n",
      "38/51 [=====================>........] - ETA: 0s - loss: 0.1146 - accuracy: 0.9597\n",
      "Epoch 97: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9623 - val_loss: 0.2668 - val_accuracy: 0.9309\n",
      "Epoch 98/100\n",
      "38/51 [=====================>........] - ETA: 0s - loss: 0.1135 - accuracy: 0.9622\n",
      "Epoch 98: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1114 - accuracy: 0.9647 - val_loss: 0.2698 - val_accuracy: 0.9309\n",
      "Epoch 99/100\n",
      "38/51 [=====================>........] - ETA: 0s - loss: 0.0912 - accuracy: 0.9688\n",
      "Epoch 99: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.0926 - accuracy: 0.9672 - val_loss: 0.2469 - val_accuracy: 0.9432\n",
      "Epoch 100/100\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 0.1078 - accuracy: 0.9688\n",
      "Epoch 100: val_loss did not improve from 0.19789\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.9685 - val_loss: 0.2375 - val_accuracy: 0.9457\n",
      "Training Completed in time:  0:00:20.118835\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# tf.keras.callbacks.ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "num_epochs=100\n",
    "num_batch_size=32\n",
    "\n",
    "checkpointer=ModelCheckpoint(filepath='audio_classifier_model/audio_classification.hdf5',verbose=1,save_best_only=True)\n",
    "start=datetime.now()\n",
    "history = model.fit(X_train,y_train,batch_size=num_batch_size,epochs=num_epochs,validation_data=(X_test,y_test),callbacks=checkpointer)\n",
    "\n",
    "duration=datetime.now()-start\n",
    "print(\"Training Completed in time: \",duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1175e532-024f-4eb1-86b6-f7e56f165b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.97125259e+02  1.31904236e+02 -1.49088402e+01  3.16940594e+01\n",
      " -1.01214485e+01  1.75017147e+01 -8.80626869e+00  2.13343978e+00\n",
      " -8.90354633e+00 -9.30018997e+00 -5.62300968e+00 -1.43834457e+01\n",
      " -1.07442446e+01 -1.93670235e+01 -1.13804512e+01 -6.68119049e+00\n",
      " -4.06562948e+00 -2.46168251e+01 -1.20662594e+01  6.49884194e-02\n",
      "  1.09240091e+00  2.43879557e-01 -4.13289070e+00 -8.47594833e+00\n",
      " -2.23178768e+01 -1.13064551e+00  9.86099052e+00  1.02230701e+01\n",
      " -1.92450392e+00 -3.13192391e+00 -2.61982083e-01 -7.27817249e+00\n",
      "  5.67436397e-01  2.14768028e+00  3.96985030e+00 -2.28359914e+00\n",
      " -3.19437838e+00 -2.21559620e+00  1.71233237e+00 -5.06967402e+00]\n",
      "[[-1.97125259e+02  1.31904236e+02 -1.49088402e+01  3.16940594e+01\n",
      "  -1.01214485e+01  1.75017147e+01 -8.80626869e+00  2.13343978e+00\n",
      "  -8.90354633e+00 -9.30018997e+00 -5.62300968e+00 -1.43834457e+01\n",
      "  -1.07442446e+01 -1.93670235e+01 -1.13804512e+01 -6.68119049e+00\n",
      "  -4.06562948e+00 -2.46168251e+01 -1.20662594e+01  6.49884194e-02\n",
      "   1.09240091e+00  2.43879557e-01 -4.13289070e+00 -8.47594833e+00\n",
      "  -2.23178768e+01 -1.13064551e+00  9.86099052e+00  1.02230701e+01\n",
      "  -1.92450392e+00 -3.13192391e+00 -2.61982083e-01 -7.27817249e+00\n",
      "   5.67436397e-01  2.14768028e+00  3.96985030e+00 -2.28359914e+00\n",
      "  -3.19437838e+00 -2.21559620e+00  1.71233237e+00 -5.06967402e+00]]\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "[2]\n",
      "['Piano']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "filename=\"4de6f231e450d27dcf04591842f0f834a7802d27590bdaf34521dd9e.wav\"\n",
    "audio,sample_rate=librosa.load(filename,res_type='kaiser_fast')\n",
    "mfccs_features=librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n",
    "mfccs_scaled_features =np.mean(mfccs_features.T,axis=0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "model=load_model('audio_classifier_model/audio_classification.hdf5')\n",
    "instrument_classes = [\"Piano\", \"Guitar\", \"Drums\", \"Vocals\"]\n",
    "LE = LabelEncoder().fit(instrument_classes)\n",
    "print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)\n",
    "\n",
    "predicted_label = np.argmax(model.predict(mfccs_scaled_features), axis=-1)\n",
    "print(predicted_label)\n",
    "\n",
    "prediction_class=LE.inverse_transform(predicted_label)\n",
    "print(prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afefbf76-271d-4a73-968d-bc8546ce833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE=LabelEncoder()\n",
    "y=to_categorical(LE.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a42c3e-4c15-436b-9f45-4df4da2e1511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
